{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate speaker embeddings and metadata for training\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from model_bl import D_VECTOR\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "pre_trained = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "C = D_VECTOR(dim_input=80, dim_cell=768, dim_emb=256).eval().to(device)\n",
    "\n",
    "if pre_trained:\n",
    "    c_checkpoint = torch.load('3000000-BL.ckpt', map_location = device)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, val in c_checkpoint['model_b'].items():\n",
    "        new_key = key[7:]\n",
    "        new_state_dict[new_key] = val\n",
    "    C.load_state_dict(new_state_dict)\n",
    "\n",
    "num_uttrs = 10\n",
    "len_crop = 128\n",
    "\n",
    "# Directory containing mel-spectrograms\n",
    "rootDir = './spmel'\n",
    "dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "print('Found directory: %s' % dirName)\n",
    "\n",
    "\n",
    "speakers = []\n",
    "for speaker in sorted(subdirList):\n",
    "    print('Processing speaker: %s' % speaker)\n",
    "    utterances = []\n",
    "    utterances.append(speaker)\n",
    "    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n",
    "    \n",
    "    # make speaker embedding\n",
    "    assert len(fileList) >= num_uttrs\n",
    "    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n",
    "    embs = []\n",
    "    for i in range(num_uttrs):\n",
    "        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n",
    "        candidates = np.delete(np.arange(len(fileList)), idx_uttrs)\n",
    "        # choose another utterance if the current one is too short\n",
    "        while tmp.shape[0] < len_crop:\n",
    "            idx_alt = np.random.choice(candidates)\n",
    "            tmp = np.load(os.path.join(dirName, speaker, fileList[idx_alt]))\n",
    "            candidates = np.delete(candidates, np.argwhere(candidates==idx_alt))\n",
    "        left = np.random.randint(0, tmp.shape[0]-len_crop)\n",
    "        melsp = torch.from_numpy(tmp[np.newaxis, left:left+len_crop, :]).to(device)\n",
    "        emb = C(melsp)\n",
    "        embs.append(emb.detach().squeeze().cpu().numpy())     \n",
    "    utterances.append(np.mean(embs, axis=0))\n",
    "    \n",
    "    # create file list\n",
    "    for fileName in sorted(fileList):\n",
    "        utterances.append(os.path.join(speaker,fileName))\n",
    "    speakers.append(utterances)\n",
    "    \n",
    "with open(os.path.join(rootDir, 'train.pkl'), 'wb') as handle:\n",
    "    pickle.dump(speakers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6325b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"spmel_original\\train.pkl\", \"rb\") as file:\n",
    "    original = pickle.load(file)\n",
    "with open(r\"spmel\\train.pkl\", \"rb\") as file:\n",
    "    new = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d63984",
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
